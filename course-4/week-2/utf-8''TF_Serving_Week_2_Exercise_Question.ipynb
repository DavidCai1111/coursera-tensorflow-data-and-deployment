{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ALCxPdSdX3NU"
   },
   "source": [
    "# Exporting an MNIST Classifier in SavedModel Format\n",
    "\n",
    "In this exercise, we will learn on how to create models for TensorFlow Hub. You will be tasked with performing the following tasks:\n",
    "\n",
    "*   Creating a simple MNIST classifier and evaluating its accuracy.\n",
    "*   Exporting it into SavedModel.\n",
    "*   Hosting the model as TF Hub Module.\n",
    "*   Importing this TF Hub Module to be used with Keras Layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "swaA66rjiRTd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMZdLgyN7gby"
   },
   "source": [
    "## Create an MNIST Classifier\n",
    "\n",
    "We will start by creating a class called `MNIST`. This class will load the MNIST dataset, preprocess the images from the dataset, and build a CNN based classifier. This class will also have some methods to train, test, and save our model. \n",
    "\n",
    "In the cell below, fill in the missing code and create the following Keras `Sequential` model:\n",
    "\n",
    "```\n",
    "    Model: \"sequential\"\n",
    "    _________________________________________________________________\n",
    "    Layer (type)                 Output Shape              Param #   \n",
    "    =================================================================\n",
    "    lambda (Lambda)              (None, 28, 28, 1)         0         \n",
    "    _________________________________________________________________\n",
    "    conv2d (Conv2D)              (None, 28, 28, 8)         80        \n",
    "    _________________________________________________________________\n",
    "    max_pooling2d (MaxPooling2D) (None, 14, 14, 8)         0         \n",
    "    _________________________________________________________________\n",
    "    conv2d_1 (Conv2D)            (None, 14, 14, 16)        1168      \n",
    "    _________________________________________________________________\n",
    "    max_pooling2d_1 (MaxPooling2 (None, 7, 7, 16)          0         \n",
    "    _________________________________________________________________\n",
    "    conv2d_2 (Conv2D)            (None, 7, 7, 32)          4640      \n",
    "    _________________________________________________________________\n",
    "    flatten (Flatten)            (None, 1568)              0         \n",
    "    _________________________________________________________________\n",
    "    dense (Dense)                (None, 128)               200832    \n",
    "    _________________________________________________________________\n",
    "    dense_1 (Dense)              (None, 10)                1290      \n",
    "    =================================================================\n",
    "\n",
    "```\n",
    "\n",
    "Notice that we are using a ` tf.keras.layers.Lambda` layer at the beginning of our model. `Lambda` layers are used to wrap arbitrary expressions as a `Layer` object:\n",
    "\n",
    "```python\n",
    "tf.keras.layers.Lambda(expression)\n",
    "```\n",
    "\n",
    "The `Lambda` layer exists so that arbitrary TensorFlow functions can be used when constructing `Sequential` and Functional API models. `Lambda` layers are best suited for simple operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST:\n",
    "    def __init__(self, export_path, buffer_size=1000, batch_size=32,\n",
    "                 learning_rate=1e-3, epochs=10):\n",
    "        self._export_path = export_path\n",
    "        self._buffer_size = buffer_size\n",
    "        self._batch_size = batch_size\n",
    "        self._learning_rate = learning_rate\n",
    "        self._epochs = epochs\n",
    "    \n",
    "        self._build_model()\n",
    "        self.train_dataset, self.test_dataset = self._prepare_dataset()\n",
    "    \n",
    "    # Function to preprocess the images.\n",
    "    def preprocess_fn(self, x):\n",
    "        \n",
    "        # EXERCISE: Cast x to tf.float32 using the tf.cast() function.\n",
    "        # You should also normalize the values of x to be in the range [0, 1].\n",
    "        x = tf.cast(x, tf.float32) / 255.0 # YOUR CODE HERE\n",
    "            \n",
    "        return x\n",
    "        \n",
    "    def _build_model(self):\n",
    "        \n",
    "        # EXERCISE: Build the model according to the model summary shown above.\n",
    "        self._model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Input(shape=(28, 28, 1), dtype=tf.uint8),\n",
    "            \n",
    "            # Use a Lambda layer to use the self.preprocess_fn function\n",
    "            # defined above to preprocess the images.\n",
    "            # YOUR CODE HERE\n",
    "            tf.keras.layers.Lambda(self.preprocess_fn),\n",
    "            \n",
    "            # Create a Conv2D layer with 8 filters, a kernel size of 3\n",
    "            # and padding='same'.\n",
    "            # YOUR CODE HERE\n",
    "            tf.keras.layers.Conv2D(kernel_size=3, filters=8, padding='same'),\n",
    "            \n",
    "            # Create a MaxPool2D() layer. Use default values.\n",
    "            # YOUR CODE HERE\n",
    "            tf.keras.layers.MaxPool2D(),\n",
    "            \n",
    "            # Create a Conv2D layer with 16 filters, a kernel size of 3\n",
    "            # and padding='same'.\n",
    "            # YOUR CODE HERE\n",
    "            tf.keras.layers.Conv2D(kernel_size=3, filters=16, padding='same'),\n",
    "            \n",
    "            # Create a MaxPool2D() layer. Use default values.\n",
    "            # YOUR CODE HERE\n",
    "            tf.keras.layers.MaxPool2D(),\n",
    "            \n",
    "            # Create a Conv2D layer with 32 filters, a kernel size of 3\n",
    "            # and padding='same'.\n",
    "            # YOUR CODE HERE\n",
    "            tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same'),\n",
    "            \n",
    "            # Create the Flatten and Dense layers as described in the \n",
    "            # model summary shown above.\n",
    "            # YOUR CODE HERE\n",
    "            tf.keras.layers.Flatten(),\n",
    "            \n",
    "            tf.keras.layers.Dense(128),\n",
    "            \n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        # EXERCISE: Define the optimizer, loss function and metrics.\n",
    "        \n",
    "        # Use the tf.keras.optimizers.Adam optimizer and set the\n",
    "        # learning rate to self._learning_rate.\n",
    "        optimizer_fn = tf.keras.optimizers.Adam(lr=self._learning_rate) # YOUR CODE HERE\n",
    "        \n",
    "        # Use sparse_categorical_crossentropy as your loss function.\n",
    "        loss_fn = \"sparse_categorical_crossentropy\" # YOUR CODE HERE\n",
    "        \n",
    "        # Set the metrics to accuracy.\n",
    "        metrics_list = [\"accuracy\"] # YOUR CODE HERE\n",
    "     \n",
    "        # Compile the model.\n",
    "        self._model.compile(optimizer_fn, loss=loss_fn, metrics=metrics_list)\n",
    "        \n",
    "    def _prepare_dataset(self):\n",
    "        \n",
    "        filePath = f\"{getcwd()}/../tmp2\"\n",
    "        \n",
    "        # EXERCISE: Load the MNIST dataset using tfds.load(). Make sure to use\n",
    "        # the argument data_dir=filePath. You should load the images as well\n",
    "        # as their corresponding labels and load both the test and train splits.\n",
    "        splits, info  = tfds.load(name=\"mnist\", data_dir=filePath, with_info=True, as_supervised=True, split=['train', 'test']) # YOUR CODE HERE\n",
    "        \n",
    "        # EXERCISE: Extract the 'train' and 'test' splits from the dataset above.\n",
    "        train_dataset, test_dataset = splits # YOUR CODE HERE\n",
    "        \n",
    "        return train_dataset, test_dataset\n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        # EXERCISE: Shuffle and batch the self.train_dataset. Use self._buffer_size\n",
    "        # as the shuffling buffer and self._batch_size as the batch size for batching. \n",
    "        dataset_tr = self.train_dataset.shuffle(self._buffer_size).batch(self._batch_size) # YOUR CODE HERE\n",
    "        \n",
    "        # Train the model for specified number of epochs.\n",
    "        self._model.fit(dataset_tr, epochs=self._epochs)\n",
    "        \n",
    "    def test(self):\n",
    "        \n",
    "        # EXERCISE: Batch the self.test_dataset. Use a batch size of 32.\n",
    "        dataset_te =self.test_dataset.batch(32) # YOUR CODE HERE\n",
    "        \n",
    "        # Evaluate the dataset\n",
    "        results = self._model.evaluate(dataset_te)\n",
    "    \n",
    "        # Print the metric values on which the model is being evaluated on.\n",
    "        for name, value in zip(self._model.metrics_names, results):\n",
    "            print(\"%s: %.3f\" % (name, value))\n",
    "            \n",
    "    def export_model(self):\n",
    "        # Save the model.\n",
    "        tf.saved_model.save(self._model, self._export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-dDAjgDe7lp4"
   },
   "source": [
    "## Train, Evaluate, and Save the Model\n",
    "\n",
    "We will now use the `MNIST` class we created above to create an `mnist` object. When creating our `mnist` object we will use a dictionary to pass our training parameters. We will then call the `train` and `export_model` methods to train and save our model, respectively. Finally, we call the `test` method to evaluate our model after training. \n",
    "\n",
    "**NOTE:** It will take about 12 minutes to train the model for 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "w6Ba6ileois3",
    "outputId": "a280b504-6619-4a1e-c020-6c787b5b76b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 151s 80ms/step - loss: 0.1506 - accuracy: 0.9548\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 141s 75ms/step - loss: 0.0781 - accuracy: 0.9761\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 141s 75ms/step - loss: 0.0669 - accuracy: 0.9791\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 142s 76ms/step - loss: 0.0597 - accuracy: 0.9816\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 142s 76ms/step - loss: 0.0542 - accuracy: 0.9828\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 32s 101ms/step - loss: 0.0633 - accuracy: 0.9807\n",
      "loss: 0.063\n",
      "accuracy: 0.981\n"
     ]
    }
   ],
   "source": [
    "# Define the training parameters.\n",
    "args = {'export_path': './saved_model',\n",
    "        'buffer_size': 1000,\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 1e-3,\n",
    "        'epochs': 5\n",
    "}\n",
    "\n",
    "# Create the mnist object. \n",
    "mnist = MNIST(**args)\n",
    "\n",
    "# Train the model.\n",
    "mnist.train()\n",
    "\n",
    "# Save the model.\n",
    "mnist.export_model()\n",
    "\n",
    "# Evaluate the trained MNIST model.\n",
    "mnist.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sotJ7pQm7umV"
   },
   "source": [
    "## Create a Tarball\n",
    "\n",
    "The `export_model` method saved our model in the TensorFlow SavedModel format in the `./saved_model` directory. The SavedModel format saves our model and its weights in various files and directories. This makes it difficult to distribute our model. Therefore, it is convenient to create a single compressed file that contains all the files and folders of our model. To do this, we will use the `tar` archiving program to create a tarball (similar to a Zip file) that contains our SavedModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tarball from the SavedModel.\n",
    "!tar -cz -f module.tar.gz -C ./saved_model ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the Tarball\n",
    "\n",
    "We can uncompress our tarball to make sure it has all the files and folders from our SavedModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "NknIrjE1ovkF",
    "outputId": "ca2a4d3b-b448-45af-cc7a-44e1096b7974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./variables/\n",
      "./variables/variables.data-00001-of-00002\n",
      "./variables/variables.data-00000-of-00002\n",
      "./variables/variables.index\n",
      "./saved_model.pb\n",
      "./assets/\n"
     ]
    }
   ],
   "source": [
    "# Inspect the tarball.\n",
    "!tar -tf module.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8LjCeO474N4"
   },
   "source": [
    "## Simulate Server Conditions\n",
    "\n",
    "Once we have verified our tarball, we can now simulate server conditions. In a normal scenario, we will fetch our TF Hub module from a remote server using the module's handle. However, since this notebook cannot host the server, we will instead point the module handle to the directory where our SavedModel is stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "C-8vmmtVxJVF",
    "outputId": "05176438-367d-4914-d38e-db61d6e69978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./variables/\n",
      "./variables/variables.data-00001-of-00002\n",
      "./variables/variables.data-00000-of-00002\n",
      "./variables/variables.index\n",
      "./saved_model.pb\n",
      "./assets/\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./module\n",
    "!mkdir -p module\n",
    "!tar xvzf module.tar.gz -C ./module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSmU1oZgxJZS"
   },
   "outputs": [],
   "source": [
    "# Define the module handle.\n",
    "MODULE_HANDLE = './module'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the TF Hub Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b2lOfoKab5Rv"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Load the TF Hub module using the hub.load API.\n",
    "model = hub.load(handle=MODULE_HANDLE) # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the TF Hub Module\n",
    "\n",
    "We will now test our TF Hub module with images from the `test` split of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dCmeWVj_ovno"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_OptionsDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "filePath = f\"{getcwd()}/../tmp2\"\n",
    "\n",
    "# EXERCISE: Load the MNIST 'test' split using tfds.load().\n",
    "# Make sure to use the argument data_dir=filePath. You\n",
    "# should load the images along with their corresponding labels.\n",
    "\n",
    "dataset = tfds.load(name=\"mnist\", data_dir=filePath, as_supervised=True, split=tfds.Split.TEST)\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# EXERCISE: Batch the dataset using a batch size of 32.\n",
    "test_dataset = dataset.batch(32) # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "wY9bVLTayn3H",
    "outputId": "72dd5ad9-359c-4f71-a054-55a2cb04d6a8"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find matching function to call loaded from the SavedModel. Got:\n  Positional arguments (3 total):\n    * Tensor(\"inputs:0\", shape=(28, 28, 1), dtype=uint8)\n    * False\n    * None\n  Keyword arguments: {}\n\nExpected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (3 total):\n    * TensorSpec(shape=(None, 28, 28, 1), dtype=tf.uint8, name='input_1')\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (3 total):\n    * TensorSpec(shape=(None, 28, 28, 1), dtype=tf.uint8, name='inputs')\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (3 total):\n    * TensorSpec(shape=(None, 28, 28, 1), dtype=tf.uint8, name='inputs')\n    * True\n    * None\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (3 total):\n    * TensorSpec(shape=(None, 28, 28, 1), dtype=tf.uint8, name='input_1')\n    * True\n    * None\n  Keyword arguments: {}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b472bd2a6ab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test the TF Hub module for a single batch of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted Labels:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mrestored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m         .format(_pretty_format_positional(args), kwargs,\n\u001b[1;32m    261\u001b[0m                 \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcrete_functions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \"\\n\\n\".join(signature_descriptions)))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0mconcrete_function_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find matching function to call loaded from the SavedModel. Got:\n  Positional arguments (3 total):\n    * Tensor(\"inputs:0\", shape=(28, 28, 1), dtype=uint8)\n    * False\n    * None\n  Keyword arguments: {}\n\nExpected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (3 total):\n    * TensorSpec(shape=(None, 28, 28, 1), dtype=tf.uint8, name='input_1')\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (3 total):\n    * TensorSpec(shape=(None, 28, 28, 1), dtype=tf.uint8, name='inputs')\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (3 total):\n    * TensorSpec(shape=(None, 28, 28, 1), dtype=tf.uint8, name='inputs')\n    * True\n    * None\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (3 total):\n    * TensorSpec(shape=(None, 28, 28, 1), dtype=tf.uint8, name='input_1')\n    * True\n    * None\n  Keyword arguments: {}"
     ]
    }
   ],
   "source": [
    "# Test the TF Hub module for a single batch of data\n",
    "for batch_data in test_dataset.take(1):\n",
    "    outputs = model(batch_data[0])\n",
    "    outputs = np.argmax(outputs, axis=-1)\n",
    "    print('Predicted Labels:', outputs)\n",
    "    print('True Labels:     ', batch_data[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model correctly predicts the labels for most images in the batch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ciRPFhPg8FWH"
   },
   "source": [
    "## Evaluate the Model Using Keras\n",
    "\n",
    "In the cell below, you will integrate the TensorFlow Hub module into the high level Keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMjnPFOjxmus"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Integrate the TensorFlow Hub module into a Keras\n",
    "# sequential model. You should use a hub.KerasLayer and you \n",
    "# should make sure to use the correct values for the output_shape,\n",
    "# and input_shape parameters. You should also use tf.uint8 for\n",
    "# the dtype parameter.\n",
    "feature_extractor = hub.KerasLayer(MODULE_HANDLE,input_shape=(28, 28, 1), output_shape=(10,), dtype=tf.uint8)\n",
    "model = tf.keras.Sequential([feature_extractor,\n",
    "                            ])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ShGHxh0Wx7lW",
    "outputId": "cce8cbc9-8f95-4965-d0cb-a8ce95e68156"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test_dataset.\n",
    "results = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "wZ6jUqbDx7s4",
    "outputId": "b408ecf5-e91f-4f5c-e147-30047b267131"
   },
   "outputs": [],
   "source": [
    "# Print the metric values on which the model is being evaluated on.\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This frees up resources for your fellow learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Shutdown and close the notebook -->\n",
    "window.onbeforeunload = null\n",
    "window.close();\n",
    "IPython.notebook.session.delete();"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST TFHub Module 4 Answer.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "advanced-deployment-scenarios-tensorflow",
   "graded_item_id": "fwoZ8",
   "launcher_item_id": "bBHO2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
